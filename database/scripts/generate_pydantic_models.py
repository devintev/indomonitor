#!/usr/bin/env -S uv run --quiet --script
# /// script
# dependencies = [
#   "pydantic>=2.4",
#   "PyYAML>=6.0",
#   "black>=23.0",
# ]
# ///
"""
Generate Pydantic models from YAML schema definitions.

Reads field sets from database/schema/field_sets/*.yaml
and table definitions from database/schema/tables/news_monitoring_tables.yaml
to generate Pydantic v2 models.

Output: database/generated/python/models/models.py
"""

import yaml
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Any

# Type mapping from YAML to Python
PYTHON_TYPE_MAP = {
    "string": "str",
    "text": "str",
    "integer": "int",
    "number": "float",
    "boolean": "bool",
    "timestamp": "datetime",
    "json": "dict[str, Any]",
    "uuid": "str",
    "array": "list",
    "object": "dict[str, Any]",
}

# SQL to Python type fallback (if type not specified but sql_type is)
SQL_TYPE_MAP = {
    "VARCHAR": "str",
    "CHAR": "str",
    "TEXT": "str",
    "INT": "int",
    "INTEGER": "int",
    "FLOAT": "float",
    "DOUBLE": "float",
    "BOOLEAN": "bool",
    "TIMESTAMP": "datetime",
    "DATETIME": "datetime",
    "DATE": "date",
    "JSON": "dict[str, Any]",
}

# Template for generated file header
FILE_HEADER = '''# =============================================================================
# AUTO-GENERATED CODE - DO NOT EDIT
# =============================================================================
# ⚠️  WARNING: This file is automatically generated from YAML schema definitions
#
# Source: ../../schema/tables/news_monitoring_tables.yaml
# Field Sets: ../../schema/field_sets/*.yaml
# Generator: ../../scripts/generate_pydantic_models.py
#
# DO NOT EDIT THIS FILE MANUALLY
# Any changes will be overwritten when code is regenerated.
#
# To make changes:
# 1. Edit YAML files in ../../schema/
# 2. Run: ./database/scripts/generate_pydantic_models.py
# 3. Generated code will update automatically
# =============================================================================

"""
Pydantic models for News Monitoring Database.

Auto-generated from YAML schema definitions.
"""

from datetime import datetime, date
from typing import Any, Literal
from pydantic import BaseModel, Field, ConfigDict


class DatabaseModel(BaseModel):
    """Base model for all database table models."""

    model_config = ConfigDict(
        populate_by_name=True,
        str_strip_whitespace=True,
        validate_assignment=True,
        extra="forbid"
    )

'''


def load_field_sets(field_sets_dir: Path) -> dict[str, dict]:
    """
    Load field sets from individual YAML files.

    Each file contains a single field set with structure:
    field_set:
      name: "set_name"
      description: "..."
      fields: [...]

    Returns:
        dict: {set_name: {description, fields}}
    """
    field_sets = {}

    if not field_sets_dir.exists():
        print(f"Warning: Field sets directory not found: {field_sets_dir}")
        return field_sets

    for yaml_file in field_sets_dir.glob("*.yaml"):
        try:
            with open(yaml_file, 'r') as f:
                data = yaml.safe_load(f)

            # Extract field_set (singular key in your schema)
            field_set = data.get("field_set")
            if field_set and "name" in field_set:
                name = field_set["name"]
                field_sets[name] = {
                    "description": field_set.get("description", ""),
                    "fields": field_set.get("fields", [])
                }
                print(f"  Loaded field set: {name} ({len(field_set.get('fields', []))} fields)")
            else:
                print(f"Warning: Invalid field set structure in {yaml_file}")

        except Exception as e:
            print(f"Error loading {yaml_file}: {e}")

    return field_sets


def load_table_schemas(tables_file: Path) -> dict[str, dict]:
    """
    Load table schemas from news_monitoring_tables.yaml.

    Returns:
        dict: {table_name: schema_definition}
    """
    if not tables_file.exists():
        raise FileNotFoundError(f"Table schemas file not found: {tables_file}")

    with open(tables_file, 'r') as f:
        data = yaml.safe_load(f)

    schemas = data.get("database_schemas", {})
    print(f"  Loaded {len(schemas)} table schemas")

    return schemas


def merge_field_sets_into_schema(schema: dict, field_sets: dict[str, dict]) -> dict:
    """
    Merge included field sets into a table schema.

    Adapted from the example script to handle field set inclusion.
    Field sets are added before table-specific fields, with deduplication.

    Args:
        schema: Table schema definition
        field_sets: Available field sets

    Returns:
        dict: Schema with field sets merged in
    """
    include_sets = schema.get("include_field_sets", [])

    if not include_sets:
        return schema

    # Collect all fields from included field sets
    merged_fields = []
    seen_field_names = set()

    for set_name in include_sets:
        if set_name not in field_sets:
            print(f"Warning: Field set '{set_name}' not found for table '{schema.get('db_table_name')}'")
            continue

        field_set = field_sets[set_name]
        for field in field_set.get("fields", []):
            field_name = field.get("name")
            if field_name and field_name not in seen_field_names:
                merged_fields.append(field)
                seen_field_names.add(field_name)

    # Add table-specific fields (skip duplicates)
    for field in schema.get("fields", []):
        field_name = field.get("name")
        if field_name and field_name not in seen_field_names:
            merged_fields.append(field)
            seen_field_names.add(field_name)

    # Update schema with merged fields
    schema_copy = schema.copy()
    schema_copy["fields"] = merged_fields

    return schema_copy


def get_python_type(field: dict) -> tuple[str, bool]:
    """
    Convert YAML field type to Python type annotation.

    Args:
        field: Field definition from YAML

    Returns:
        tuple: (python_type, is_optional)
    """
    field_type = field.get("type", "")
    sql_type = field.get("sql_type", "")
    required = field.get("required", True)
    enum_values = field.get("enum")

    # Handle enums as Literal types
    if enum_values:
        enum_str = ", ".join([f'"{v}"' for v in enum_values])
        base_type = f"Literal[{enum_str}]"
    # Map from type field
    elif field_type in PYTHON_TYPE_MAP:
        base_type = PYTHON_TYPE_MAP[field_type]
    # Fallback to SQL type
    elif sql_type:
        sql_base = sql_type.split("(")[0].upper()
        base_type = SQL_TYPE_MAP.get(sql_base, "str")
    else:
        base_type = "str"  # Ultimate fallback

    # Determine if optional
    is_optional = not required or field.get("computed", False)

    return base_type, is_optional


def generate_field_definition(field: dict) -> str:
    """
    Generate a single Pydantic field definition.

    Args:
        field: Field definition from YAML

    Returns:
        str: Python field definition line
    """
    field_name = field.get("name", "unknown")
    description = field.get("description", "")
    default_value = field.get("default")

    # Get Python type
    base_type, is_optional = get_python_type(field)

    # Build type annotation
    if is_optional:
        type_annotation = f"{base_type} | None"
    else:
        type_annotation = base_type

    # Build Field() arguments
    field_args = []

    # SQL-specific defaults that shouldn't be used in Python
    sql_defaults = [
        "CURRENT_TIMESTAMP",
        "CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP",
        "NOW()",
    ]

    # Handle defaults
    if default_value and default_value not in sql_defaults:
        # String defaults need quotes
        if isinstance(default_value, str) and base_type == "str":
            field_args.append(f'default="{default_value}"')
        else:
            field_args.append(f'default={default_value}')
    elif is_optional:
        field_args.append('default=None')
    else:
        field_args.append('...')  # Required field

    # Add description
    if description:
        # Escape quotes in description
        escaped_desc = description.replace('"', '\\"')
        field_args.append(f'description="{escaped_desc}"')

    field_call = f"Field({', '.join(field_args)})"

    return f"    {field_name}: {type_annotation} = {field_call}"


def generate_model(schema_name: str, schema: dict, field_sets: dict[str, dict]) -> str:
    """
    Generate a complete Pydantic model class.

    Args:
        schema_name: Name of the schema (table)
        schema: Schema definition
        field_sets: Available field sets for merging

    Returns:
        str: Complete Python class definition
    """
    # Merge field sets into schema
    merged_schema = merge_field_sets_into_schema(schema, field_sets)

    # Extract metadata
    class_name = schema.get("python_class_name", schema_name)
    title = schema.get("title", class_name)
    table_name = schema.get("db_table_name", schema_name)

    # Start class definition
    lines = []
    lines.append(f"\nclass {class_name}(DatabaseModel):")

    # Docstring
    docstring = f'"""{title}.\n    \n    Table: {table_name}\n    Database: indomonitor\n    """'
    lines.append(f"    {docstring}")

    # Generate fields
    fields = merged_schema.get("fields", [])
    if not fields:
        lines.append("    pass  # No fields defined")
    else:
        lines.append("")
        for field in fields:
            field_def = generate_field_definition(field)
            lines.append(field_def)

    return "\n".join(lines)


def format_with_black(file_path: Path) -> None:
    """Format Python file with Black."""
    try:
        result = subprocess.run(
            ["black", "--quiet", str(file_path)],
            capture_output=True,
            text=True
        )
        if result.returncode == 0:
            print(f"  Formatted with Black: {file_path.name}")
        else:
            print(f"Warning: Black formatting failed: {result.stderr}")
    except FileNotFoundError:
        print("Warning: Black not found, skipping formatting")
    except Exception as e:
        print(f"Warning: Error running Black: {e}")


def main():
    """Main generation logic."""
    print("\n=== Pydantic Model Generator ===\n")

    # Setup paths
    script_dir = Path(__file__).parent
    database_dir = script_dir.parent
    schema_dir = database_dir / "schema"
    field_sets_dir = schema_dir / "field_sets"
    tables_file = schema_dir / "tables" / "news_monitoring_tables.yaml"
    output_dir = database_dir / "generated" / "python" / "models"
    output_file = output_dir / "models.py"

    print(f"Schema directory: {schema_dir}")
    print(f"Output directory: {output_dir}\n")

    # Load field sets
    print("Loading field sets...")
    field_sets = load_field_sets(field_sets_dir)
    print()

    # Load table schemas
    print("Loading table schemas...")
    schemas = load_table_schemas(tables_file)
    print()

    # Generate models
    print("Generating Pydantic models...")
    model_classes = []

    for schema_name, schema in schemas.items():
        print(f"  Generating model: {schema.get('python_class_name', schema_name)}")
        model_code = generate_model(schema_name, schema, field_sets)
        model_classes.append(model_code)

    # Combine all models
    full_code = FILE_HEADER + "\n".join(model_classes) + "\n"

    # Ensure output directory exists
    output_dir.mkdir(parents=True, exist_ok=True)

    # Write output
    print(f"\nWriting models to: {output_file}")
    with open(output_file, 'w') as f:
        f.write(full_code)

    # Format with Black
    format_with_black(output_file)

    # Create __init__.py
    init_file = output_dir / "__init__.py"
    print(f"Creating: {init_file.name}")

    # Extract all class names
    class_names = [schema.get('python_class_name', name) for name, schema in schemas.items()]

    # Build imports and exports
    imports_str = ',\n    '.join(class_names)
    exports_str = ',\n    '.join([f'"{name}"' for name in class_names])

    init_content = f'''"""
Pydantic models for News Monitoring Database.

Auto-generated from YAML schema definitions.
"""

from .models import (
    DatabaseModel,
    {imports_str}
)

__all__ = [
    "DatabaseModel",
    {exports_str}
]
'''

    with open(init_file, 'w') as f:
        f.write(init_content)

    format_with_black(init_file)

    print(f"\n✓ Successfully generated {len(model_classes)} Pydantic models")
    print(f"✓ Output: {output_file.relative_to(database_dir.parent)}")


if __name__ == "__main__":
    main()
